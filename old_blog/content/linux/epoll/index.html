<!DOCTYPE html>
<html>

<head>
    <meta http-equiv="pragma" content="no-cache">
    <meta http-equiv="cache-control" content="no-cache">
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>linux I/O多路复用之epoll</title>
    <link rel="stylesheet" href="../../../style.css">
    <link rel="stylesheet" href="contentStyle.css">
</head>

<body>
    <div class="head">
        <div class="header">
            <div class="name">
                <p>CC &nbsp &nbsp<small>Personal Blog</small></p>
            </div>
            <nav class="navigation">
                <ul>
                    <li><a href="../../../index.html">首页</a></li>
                    <li><a href="/about.html">关于</a></li>
                </ul>
            </nav>
        </div>
    </div>
    <div class="content">
        <div class="content-left">
            <h2>linux I/O多路复用之epoll</h2>
            <small><i class="fa fa-calender"></i><span>2021-5-15</span><i
                    class="fa fa-th-list"></i><span>linux</span></small>
            <hr>
            <article>
                <h4>1、epoll的原理和用法</h4>
                <p>设想一个场景,有100万用户同时与一个进程保持着tcp连接，而每一时刻只有几十个或者几百个连接时活跃的（接收到TCP包），也就是说，在每一时刻，进程只需要处理这100万连接中的小部分连接。</p>
                <p>那么，如何高效的处理这种场景呢？进程是否在每次询问操作系统收集有事件发生的TCP连接时，把这100万的连接告诉操作系统，然后由操作系统找出其中有事件发生的几百个连接呢？实际上，在linux内核2.4以前，那时的select或者poll事件驱动方式就是这样做的。</p>
                <p>这里有个非常明显的问题，即在某一个时刻，进程收集有事件的连接时，其实这100万的连接
                    中大部分是没有事件发生的。因此，如果每次收集事件时，都把这100万的连接的套接字传递给操作系统（这首先就是用户态内存到内核态内存的大量复制），而由操作系统内核寻找这些连接上有没有未处理的事件，将会是巨大的资源消耗，然而select和poll就是这样做的，因此他们最多只能处理几千个并发连接。</p>
                <p>而epoll不这样做，它在linux内核中申请了一个简易的文件系统，把原先的一个select或者poll调用分成了三个部分：
                    <ol>
                        <li>调用epoll_create建立一个eopll对象（在epoll文件系统中给这个句柄分配资源）</li>
                        <li>调用epoll_ctl向epoll中添加这100万个连接的套接字</li>
                        <li>调动epoll_wait收集发生事件的连接</li>
                    </ol>
                </p>
                <p>这样，只需要在进程启动时建立一个epoll对象，并在需要的时候向他添加或者删除连接就可以了，因此，在实际收集事件时，epoll_wait的效率就非常高，因为调用epoll_wait时并没有向他传递这100万的连接，内核也不需要遍历全部的连接。</p>
                <p>那么，linux内核是如何实现以上的想法呢？下面以linux内核2.6.35版本为例，简单说明epoll是如何高效处理事件的。</p>
                <p>当某一个进程调用epoll_create方法时，linux内核会创建一个eventpoll的结构体，这个结构体中有两个成员与epoll的使用方式密切相关，如下所示：</p>
                <div class="code">
                    <pre class="pre-code"><code class="code-content">struct eventpoll{
    ...
    /*红黑树的根节点，这棵树中存储着所有添加到epoll中的事件，也就是epoll监控的事件*/
    struct rb_root rbr;
    //双向链表rdllist保存着将要通过epoll_wait返回给用户，满足条件的事件
    struct list_head rdllist;
};</code></pre>
                </div>
                <p>下图为epoll内部的主要数据结构示意图：</p>
                <div class="picture">
                    <img src="image/epoll原理示意图.jpg" alt="epoll原理示意图">
                </div>
                <p>每一个epoll对象有独立的eventpoll结构体，这个结构体会在内核空间中创造独立的内存，用于存储使用epoll_ctl方法向epoll对象中添加进来的事件。这些事件都会挂到rbr红黑树中，这样，重复添加的事件就可以通过红黑树而高效的识别出来（epoll_ctl方法会很快）。</p>
                <p>所有添加到epoll中的事件都会与设备（如网卡）驱动程序简历回调关系，也就是说，相应的事件发生时会调用这里的回调方法。这个回调方法在内核中叫做ep_poll_callback，它会把这样的事件放到上面的rdllist双向链表中。</p>
                <p>在epoll中，对于每个事件都会建立一个epitem结构体，如下所示：</p>
                <div class="code">
                    <pre class="pre-code"><code class="code-content">struct epitem{
    //红黑树节点
    struct rb_node rbn;
    //双向链表节点
    struct list_head rdllink;
    //事件句柄等信息
    struct epoll_filefd ffd;
    //指向其所属的eventpoll对象
    struct eventpoll *ep;
    //期待的事件类型
    struct epoll_event event;
    ...
};</code></pre>
                </div>
                <p>这里包含每一个事件对应着的信息。</p>
                <p>当调用epoll_wait检查是否有发生事件的连接时，只是检查eventpoll对象中的rdllist双向链表中是否有epitem元素而已，如果rdllist链表不为空，则把这里的事件复制到用户态内存中，同时将事件数量返回给用户。因此epoll_wait的效率非常高。epoll_ctl在向epoll对象中添加、修改、删除事件时，从rbr红黑树中查找事件也非常快，也就是说，epoll是非常高效的，它可以轻易的处理百万级别的并发连接。</p>
                <h4>2、如何使用epoll</h4>
                <p>epoll通过下面3个epoll系统调用为用户提供服务。</p>
                <h5>（1） epoll_create系统调用</h5>
                <p>epoll_create在C库中的原型如下：</p>
                <div class="code"><pre class="pre-code"><code class="code-content">int epoll_create(int size);</code></pre></div>
                <p>epoll_create返回一个句柄，之后epoll的使用都将依靠这个句柄来标识。参数size是告诉epoll所要处理的大致事件数目。不再使用epoll时，必须调用close关闭这个句柄。</p>
                <p>注意：size参数只是告诉内核这个epoll对象会处理的事件大致数目，而不是能够处理的最大个数。在linux最新的一个内核版本的实现中，这个size参数没有任何意义。</p>
                <h5>（2）epoll_ctl系统调用</h5>
                <p>epoll_ctl在C库中的原型如下</p>
                <div class="code"><pre class="pre-code"><code class="code-content">int epoll_ctl(int epfd,int op,int fd,struct epoll_event* event);</code></pre></div>
                <p>epoll_ctl向epoll对象中添加，删除，修改感兴趣的事件，返回0表示成功，否则返回-1，此时需要根据errno错误码判断错误类型。epoll_wait方法返回的事件必然是通过epoll_ctl添加到epoll中的。参数epfd是epoll_create返回的句柄，而op参数的意义如下：</p>
                <div class="table">
                    <table>
                        <caption><strong>epoll_ctl系统调用中第2个参数的取值意义</strong></caption>
                        <tr><th>op的取值</th><th>意义</th></tr>
                        <tr><td>EPOLL_CTL_ADD</td><td>添加新的事件到epoll中</td></tr>
                        <tr><td>EPOLL_CTL_MOD</td><td>修改epoll中的事件</td></tr>
                        <tr><td>EPOLL_CTL_DEL</td><td>删除epoll中的事件</td></tr>
                    </table>
                </div>
                <p>第3个参数fd是待监测的连接套接字，第4个参数在告诉epoll对什么样的事件感兴趣，它使用了epoll_event结构体，在上文介绍过的epoll实现机制会为每一个事件创建epitem结构体，而在epitem中有一个epoll_event类型的event成员。下面看一下epoll_event的定义：</p>
                <div class="code"><pre class="pre-code"><code class="code-content">struct epoll_event{
    __uint32_t events;
    epoll_data_t data;
};</code></pre></div>
                <p>events的取值如下：</p>
                <div class="table">
                    <table>
                        <caption><strong>epoll_event中的events的取值意义</strong></caption>
                        <tr><th>events的取值</th><th>意义</th></tr>
                        <tr><td>EPOLLIN</td><td>表示对应的连接上有数据可以读出（TCP连接的远端主动关闭连接，也相当于可读事件，因为需要处理发送来的FIN包）</td></tr>
                        <tr><td>EPOLLOUT</td><td>表示对应的连接上可以写入数据发送（主动向上游发起的非阻塞的TCP连接，连接建立成功的事件相当于可写事件）</td></tr>
                        <tr><td>EPOLLRDHUP</td><td>表示TCP连接的远端关闭或者半关闭连接</td></tr>
                        <tr><td>EPOLLPRI</td><td>表示对应的连接上有紧急数据需要读</td></tr>
                        <tr><td>EPOLLERR</td><td>表示对应的连接上发生错误</td></tr>
                        <tr><td>EPOLLHUP</td><td>表示对应的连接被挂起</td></tr>
                        <tr><td>EPOLLET</td><td>表示将触发方式设置为边缘触发（ET），系统默认为水平触发（LT）</td></tr>
                        <tr><td>EPOLLONESHOT</td><td>表示这个事件只处理一次，下次处理时需要重新加入epoll</td></tr>
                    </table>
                </div>
                <p>而data成员是一个epoll_data联合，定义如下：</p>
                <div class="code"><pre class="pre-code"><code class="code-content">typedef union epoll_data{
    void *ptr;
    int fd;
    uint32_t u32;
    uint64_t u64;
} epoll_data_t</code></pre></div>
                <h5>（3）epoll_wait系统调用</h5>
                <p>epoll_wait在C库中的原型如下：</p>
                <div class="code"><pre class="pre-code"><code class="code-content">int epoll_wait(int epfd,struct epoll_event* events,int maxevents,int timeout);</code></pre></div>
                <p>收集在epoll监控的事件中已经发生的事件，如果epoll中没有任何一个事件发生，则最对多等待timeout毫秒后返回。epoll_wait的返回值表示当前发生的事件个数，如果返回0，则表示本次调用中没有事件发生，如果返回-1，则表示出现错误，需要检查errno错误码半段错误类型。第1个参数epfd是epoll的描述符。第2个参数events则是分配好的epoll_event结构体数组，epoll将会把发生的事件复制到events数组中（events不可以是空指针，内核只负责把数据复制到这个events数组中，不会去帮助我们在用户态分配内存。内核这种做法效率很高）。第3个参数maxevents表示本次可以返回的最大事件数目，通常maxevents参数与预分配的events数组的大小是相等的。第4个参数timeout表示在没有检测到事件发生时最多等待的事件（单位为毫秒），如果timeout为0，则表示epoll_wait在rdllist链表中为空，立刻返回，不会等待。</p>
                <p>epoll有两种工作模式：LT（水平触发）模式和ET（边缘触发）模式。默认情况下，epoll采用LT模式工作，这是可以处理阻塞和非阻塞套接字，可以通过EPOLLET将一个事件改为ET模式。ET模式额效率要比LT模式高，它只支持非阻塞套接字。ET模式与LT模式的区别在于，当一个新的事件到来时，ET模式下当然可以从epoll_wait调用中获取到这个事件，可是如果这次没有把这个事件对应的套接字缓冲区处理完，在这个套接字没有新的事件到来时，在ET模式下时无法再次从epoll_wait调用中获取这个事件的；而LT模式则相反，只要一个事件对应的套接字缓冲区还有数据，就总能从epoll_wait中获取这个事件。因此，在LT模式下开发基于epoll的应用要简单一些，不太容易出错，而在ET模式下，如果没有彻底地将缓冲区数据处理完，则会导致缓冲区中的用户请求得不到响应。</p>
            </article>
            <br>
            <p style="color:red;text-indent: 0em;">--文章摘自"深入理解nginx模块开发与架构第2版 9.6章节"</p>
        </div>
</body>
</html>
